- 什么时候使用异常检测算法，什么时候使用有监督学习
  - 当正例和负例的数量比例接近时，可以使用有监督学习算法；但是当负例的数量远远小于正例的数量时，应该使用异常检测算法。


# 推荐系统
- 重要性
  - 是很多公司的核心的盈利的算法，如亚马逊、Netflix
  - 但是并不是当前学术研究的前沿热点
- 手动选择特征与算法选择特征
  - 推荐系统是算法选择特征的代表
  - 有哪些算法是算法选择特征的？



# 推荐问题的描述
- 推荐问题中涉及的变量
  - $n_{u}$：用户的数量
  - $n_{m}$：电影的数量
  - $r(i,j)$：用户 $j$ 是否对电影 $i$ 进行打分？如果打过则为 1，未打过则为 0
  - $y(i,j)$：用户$j$ 是否对电影 $i$ 的评分，可以是 0-5，或者 1-5，以及类似的评分体系。由于用户并不是看过并且评价过每一部电影，因此用户对一些电影的打分是空缺的，推荐系统的目的就是要推断这些空缺的合理的值并以此为依据向用户进行合适的推荐。
- 推荐问题要解决什么问题
  - 推荐系统希望借助已有的用户对一些目标对象（如电影）的打分，预测用户对未打分对象的评价，并以此为基础向用户推荐信息。

# 基于内容的推荐
- 基本策略：
  1. 假设存在电影的多个特征（Features，n个，内容可以是`浪漫程度`、`动作程度`、`科幻程度`等），并且针对每一个电影，都知道这个电影的特征向量（即这个电影在不同特征维度上的打分）。
  2. 根据用户已有的打分情况，使用线性回归的方法推算用户对不同特征的偏好权重。
  3. 最后基于上述推算得来的权重和未打分电影的特征向量，推算用户对未打分电影的可能评分，进而向其推荐电影。
- 基于内容推荐的弊端
  - 这种方法基于`所有电影的特征向量已知`的假设，事实上电影的不同维度上的特征并没有一个“标准答案”，因此实际操作中这种方法并不好执行。
  - 从特征的筛选和学习的角度讲，这种算法并不能实现对特征的自动学习。

# 协同过滤
- 与基于内容推荐相对的另一种推荐算法
  - 基于内容的推荐算法假设每一部电影都已经有一个公正的打分了，并以此为基于推算用户偏好。
  - 那么和上述假设相反，现在我们假设我们已经得知了用户对不同特征的偏好 $\theta$ 以及其对电影的打分，那么相应的我们就可以同样使用线性回归算法推算出不同电影的特征向量（Features of movies）$x$。
    - 当然，这种算法也有同样的不足，就是实际上我们是拿不到用户对不同特征的偏好的（除非专门去做问卷调查），因此实际情况中同样无法执行。
  - 上述两种方法有点像先有鸡还是先有蛋的问题。针对这种情况，有了协同过滤算法。协同过滤算法的基本步骤是：
    1. 随机初始化用户的偏好向量 $\theta$
    2. 由上述随机初始化的偏好向量计算电影特征
    3. 由电影特征计算偏好向量
    4. 不断循环，直到结束
- 更高效的协同过滤算法
  - 由于上述协同过滤算法需要反复的计算，因此使用更高效的算法：将上述两个过程的损失函数合并，使用合并后的损失函数对用户的特征向量 $\theta$ 和电影的特征向量 $x$ 进行同时优化。

# 协同过滤的向量化表示
- 由用户对不同电影评分组成的矩阵，$n_{m} * n_{u}$ 。根据这个矩阵，使用协同过滤算法可以对不同电影的特征矩阵（$X,n_{m} * n$，转置过的）、不同用户的特征矩阵（$\theta,n_{u} * n$），则对未标记电影进行预测为 $X*\theta^{T}, n_{m} * n_{u}$

# 均值归一化（Mean Normalization）
- 如果一个用户是新用户，即完全没有对任何电影有过评分，那么如何向其推荐电影呢？比较常见的思路就是将大家都认为好的电影推荐给他，也就是使用均值的方式去评价电影的好坏。
- 步骤
  1. 首先计算不同电影的评分均值
  2. 将所有的评分减去对应的均值，得到一个新的矩阵
  3. 新参评的问号处应得到0，也就是该电影的均值

# 相似电影推荐
- 使用特征空间中两个电影的范数距离表示两个电影的相似程度
